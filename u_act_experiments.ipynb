{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Shaped Automated Container Terminal Scheduling Experiments\n",
    "\n",
    "This notebook implements and experiments with the Digital Twin-driven real-time collaborative scheduling system for U-shaped automated container terminals based on the research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from u_act_digital_twin import UACTEnvironment, PPOAgent, DigitalTwinVisualization, compare_scheduling_rules\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "Initialize the U-shaped automated container terminal environment with different configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize environment\n",
    "env_small = UACTEnvironment(num_containers=40, num_agvs=3)\n",
    "env_medium = UACTEnvironment(num_containers=100, num_agvs=5)\n",
    "env_large = UACTEnvironment(num_containers=200, num_agvs=10)\n",
    "\n",
    "print(\"Environment initialized with:\")\n",
    "print(f\"Small: {env_small.num_containers} containers, {env_small.num_agvs} AGVs\")\n",
    "print(f\"Medium: {env_medium.num_containers} containers, {env_medium.num_agvs} AGVs\")\n",
    "print(f\"Large: {env_large.num_containers} containers, {env_large.num_agvs} AGVs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. State Space Analysis\n",
    "\n",
    "Examine the state representation of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get initial state\n",
    "state = env_medium.get_state()\n",
    "\n",
    "state_features = [\n",
    "    \"Num Import Containers\", \"Num Export Containers\",\n",
    "    \"Mean Import CR\", \"Std Import CR\",\n",
    "    \"Mean Export CR\", \"Std Export CR\",\n",
    "    \"Mean Remaining Time\", \"Std Remaining Time\",\n",
    "    \"Mean AGV Load\", \"Std AGV Load\",\n",
    "    \"Mean YC Load\", \"Std YC Load\",\n",
    "    \"Mean AGV Queue Length\", \"Std AGV Queue Length\",\n",
    "    \"Mean AGV Wait Time\", \"Std AGV Wait Time\",\n",
    "    \"Mean ET Queue Length\", \"Std ET Queue Length\",\n",
    "    \"Mean ET Wait Time\", \"Std ET Wait Time\"\n",
    "]\n",
    "\n",
    "state_df = pd.DataFrame({\n",
    "    'Feature': state_features,\n",
    "    'Value': state\n",
    "})\n",
    "\n",
    "print(\"Initial State Representation:\")\n",
    "print(state_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PPO Agent Training\n",
    "\n",
    "Train the PPO agent for dynamic scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(env, num_episodes=500):\n",
    "    \"\"\"Train PPO agent on given environment\"\"\"\n",
    "    agent = PPOAgent(state_dim=env.state_dim, action_dim=6)\n",
    "    metrics_history = []\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        episode_rewards = []\n",
    "        \n",
    "        for step in range(200):  # Max steps per episode\n",
    "            action, _ = agent.get_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            episode_rewards.append(reward)\n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        metrics_history.append({\n",
    "            'episode': episode,\n",
    "            'avg_reward': np.mean(episode_rewards),\n",
    "            'makespan': env.makespan,\n",
    "            'tci': env.terminal_congestion_index\n",
    "        })\n",
    "        \n",
    "        if episode % 100 == 0:\n",
    "            print(f\"Episode {episode}: Reward = {np.mean(episode_rewards):.4f}\")\n",
    "    \n",
    "    return agent, metrics_history\n",
    "\n",
    "# Train on medium environment\n",
    "print(\"Training PPO agent on medium-scale environment...\")\n",
    "trained_agent, training_metrics = train_agent(env_medium, num_episodes=500)\n",
    "\n",
    "# Plot training progress\n",
    "metrics_df = pd.DataFrame(training_metrics)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(metrics_df['episode'], metrics_df['avg_reward'])\n",
    "plt.title('Average Reward')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(metrics_df['episode'], metrics_df['makespan'])\n",
    "plt.title('Makespan')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Time')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(metrics_df['episode'], metrics_df['tci'])\n",
    "plt.title('Terminal Congestion Index')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('TCI (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scheduling Rule Comparison\n",
    "\n",
    "Compare the performance of different scheduling rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare scheduling rules\n",
    "comparison_results = compare_scheduling_rules()\n",
    "\n",
    "print(\"Scheduling Rule Comparison:\")\n",
    "print(comparison_results)\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Makespan comparison\n",
    "axes[0].bar(comparison_results['Rule'], comparison_results['Makespan'], color='skyblue')\n",
    "axes[0].set_title('Makespan Comparison')\n",
    "axes[0].set_ylabel('Makespan')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# TCI comparison\n",
    "axes[1].bar(comparison_results['Rule'], comparison_results['TCI'], color='lightcoral')\n",
    "axes[1].set_title('Terminal Congestion Index Comparison')\n",
    "axes[1].set_ylabel('TCI (%)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Total waiting time comparison\n",
    "axes[2].bar(comparison_results['Rule'], comparison_results['Total Waiting'], color='lightgreen')\n",
    "axes[2].set_title('Total Waiting Time Comparison')\n",
    "axes[2].set_ylabel('Waiting Time')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Impact of AGV Quantity\n",
    "\n",
    "Analyze how the number of AGVs affects scheduling performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_agv_impact():\n",
    "    \"\"\"Analyze impact of AGV quantity on performance\"\"\"\n",
    "    agv_counts = [3, 5, 8, 10]\n",
    "    results = []\n",
    "    \n",
    "    for num_agvs in agv_counts:\n",
    "        env = UACTEnvironment(num_containers=100, num_agvs=num_agvs)\n",
    "        state = env.reset()\n",
    "        \n",
    "        # Run simulation with PPO agent\n",
    "        for step in range(200):\n",
    "            action = np.random.randint(0, 6)  # Random action for demonstration\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        results.append({\n",
    "            'Num_AGVs': num_agvs,\n",
    "            'Makespan': env.makespan,\n",
    "            'TCI': env.terminal_congestion_index,\n",
    "            'Total_Waiting': env.total_waiting_time\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "agv_impact_df = analyze_agv_impact()\n",
    "print(\"AGV Quantity Impact Analysis:\")\n",
    "print(agv_impact_df)\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].plot(agv_impact_df['Num_AGVs'], agv_impact_df['Makespan'], 'o-', linewidth=2)\n",
    "axes[0].set_xlabel('Number of AGVs')\n",
    "axes[0].set_ylabel('Makespan')\n",
    "axes[0].set_title('Impact of AGV Quantity on Makespan')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(agv_impact_df['Num_AGVs'], agv_impact_df['TCI'], 'o-', linewidth=2, color='red')\n",
    "axes[1].set_xlabel('Number of AGVs')\n",
    "axes[1].set_ylabel('TCI (%)')\n",
    "axes[1].set_title('Impact of AGV Quantity on Congestion')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Digital Twin Visualization\n",
    "\n",
    "Create comprehensive visualization of the digital twin environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "viz_env = UACTEnvironment(num_containers=50, num_agvs=5)\n",
    "viz = DigitalTwinVisualization(viz_env)\n",
    "\n",
    "# Run simulation and update visualization\n",
    "metrics = []\n",
    "state = viz_env.reset()\n",
    "\n",
    "for step in range(100):\n",
    "    action = np.random.randint(0, 6)\n",
    "    state, reward, done, _ = viz_env.step(action)\n",
    "    \n",
    "    metrics.append({\n",
    "        'makespan': viz_env.makespan,\n",
    "        'tci': viz_env.terminal_congestion_index,\n",
    "        'avg_reward': reward\n",
    "    })\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        viz.update_plots(metrics)\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print(\"Visualization completed!\")\n",
    "print(f\"Final Metrics: Makespan = {viz_env.makespan}, TCI = {viz_env.terminal_congestion_index:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Real-time Performance Monitoring\n",
    "\n",
    "Monitor real-time performance metrics during scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_real_time_performance():\n",
    "    \"\"\"Monitor real-time performance metrics\"\"\"\n",
    "    env = UACTEnvironment(num_containers=80, num_agvs=6)\n",
    "    state = env.reset()\n",
    "    \n",
    "    metrics_over_time = []\n",
    "    \n",
    "    for step in range(150):\n",
    "        action = np.random.randint(0, 6)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # Collect metrics\n",
    "        agv_utilization = np.mean([agv['load_rate'] for agv in env.agvs])\n",
    "        yc_utilization = np.mean([yc['load_rate'] for yc in env.ycs])\n",
    "        \n",
    "        metrics_over_time.append({\n",
    "            'step': step,\n",
    "            'reward': reward,\n",
    "            'agv_utilization': agv_utilization,\n",
    "            'yc_utilization': yc_utilization,\n",
    "            'completed_tasks': len(env.completed_tasks),\n",
    "            'total_waiting': env.total_waiting_time\n",
    "        })\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    return pd.DataFrame(metrics_over_time)\n",
    "\n",
    "real_time_metrics = monitor_real_time_performance()\n",
    "\n",
    "# Plot real-time metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "axes[0, 0].plot(real_time_metrics['step'], real_time_metrics['reward'])\n",
    "axes[0, 0].set_title('Real-time Reward')\n",
    "axes[0, 0].set_xlabel('Time Step')\n",
    "axes[0, 0].set_ylabel('Reward')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(real_time_metrics['step'], real_time_metrics['agv_utilization'], label='AGV Utilization')\n",
    "axes[0, 1].plot(real_time_metrics['step'], real_time_metrics['yc_utilization'], label='YC Utilization')\n",
    "axes[0, 1].set_title('Equipment Utilization')\n",
    "axes[0, 1].set_xlabel('Time Step')\n",
    "axes[0, 1].set_ylabel('Utilization Rate')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(real_time_metrics['step'], real_time_metrics['completed_tasks'])\n",
    "axes[1, 0].set_title('Task Completion Progress')\n",
    "axes[1, 0].set_xlabel('Time Step')\n",
    "axes[1, 0].set_ylabel('Completed Tasks')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(real_time_metrics['step'], real_time_metrics['total_waiting'])\n",
    "axes[1, 1].set_title('Total Waiting Time')\n",
    "axes[1, 1].set_xlabel('Time Step')\n",
    "axes[1, 1].set_ylabel('Waiting Time')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}